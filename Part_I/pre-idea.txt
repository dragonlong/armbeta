For this task of using a robot arm grasping goods with rgb-d camera, we could think from the following directions:
visual robotic object grasping from RGB-D Data
1. 2D perception + motion planning(baseline);
2. RL imitate learning from humans;
3. 2d/3d object detection + 3D matching;
5. 3D segmentation from Point clouds;


Available Code & Project:
1. amazon picking challenge:(2016)
https://github.com/kanster/amazonpickingchallenge
https://github.com/andyzeng/apc-vision-toolbox
http://pwurman.org/amazonpickingchallenge/results.shtml
2. Frustum PointNets for 3D Object Detection from RGB-D Data(CVPR2018):
https://github.com/charlesq34/frustum-pointnets
http://stanford.edu/~rqi/frustum-pointnets/
3. SPLATNet: Sparse Lattice Networks for Point Cloud Processing (CVPR2018):
https://github.com/NVlabs/splatnet
4. 3D Bounding Box Estimation Using Deep Learning and Geometry
https://github.com/smallcorgi/3D-Deepbox
Next: Finding more 3D match, indoor object detection, robot grasping
5. RSNet(CVPR2018)
https://github.com/qianguih/RSNet

Useful infos:
1. 2018 CVPR-Notes:
https://github.com/bexcite/cvpr2018-notes
2. CVPR SLAM workshop:Deep Learning for Visual SLAM workshop, 3D vision
http://visualslam.ai/
3. Object Recognition, Detection and 6D Pose Estimation(State of the Art Methods and Datasets)
http://rkouskou.gitlab.io/research/6D_Object.html
4. CMU object aware SLAM:
https://www.cs.cmu.edu/~katef/
5. Yangbin in Toronto and Uber ATG:
http://www.cs.toronto.edu/~byang/
6. Amazon Research Scientist:
http://shoefer.github.io/me/

Important Papers to follow:
1. 3DMV: Joint 3D-Multi-View Prediction for 3D Semantic Scene Segmentation(CVPR2018)
https://arxiv.org/abs/1803.10409
http://www.niessnerlab.org/publications.html
2. Frustum PointNets for 3D Object Detection from RGB-D Data
http://stanford.edu/~rqi/frustum-pointnets/
3. ScanNet v2: Richly-annotated 3D Reconstructions of Indoor Scenes
http://www.scan-net.org/
4. Pointwise Convolutional Neural Networks:
http://103.24.77.34:8080/scenenn/home/cvpr18/
5. 3D Object Detection Evaluation 2017:
http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=3d


Also some most recent research on robotics perception

Questions:
1. What are the best detection representations that I could send to control part
     3D Segmentation, or 3D bounding box, or 6D Pose and Position;
2. Robot picking/grasping simulation in ROS, some models;
3. GPU(2*GTX 1080Ti), RAM >32G;Tensorflow 1.5, Pytorch(?); Caffe(local very easy), New Caffe(?)
4.
